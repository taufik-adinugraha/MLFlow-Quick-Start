{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6357ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import warnings\n",
    "import mlflow\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439524e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/02/25 08:16:05 INFO mlflow.tracking.fluent: Experiment with name 'iris' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./myml/1', experiment_id='1', lifecycle_stage='active', name='iris', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to tracking URI\n",
    "# URI can either be a HTTP/HTTPS URI for a remote server, or a local path to log data to a directory\n",
    "mlflow.set_tracking_uri('./myml') \n",
    "\n",
    "# set experiment name to organize runs\n",
    "experiment_name = 'iris'\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f63b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "data = load_iris()\n",
    "x, y = data.data, data.target\n",
    "\n",
    "# split data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2781b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_class': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 3,\n",
    "    'max_depth': 2,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'subsample': 0.7,\n",
    "    'seed': 42,\n",
    "}\n",
    "train_params = {\n",
    "    'num_boost_round': 200,\n",
    "    'verbose_eval': 50,\n",
    "    'early_stopping_rounds': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3440be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(y_proba):\n",
    "    y_pred = y_proba.argmax(axis=1)\n",
    "    auc = roc_auc_score(y_val, y_proba, multi_class='ovo')\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    mlflow.log_metrics({\"val_roc_auc\": auc, \"val_accuracy\": acc})\n",
    "    return auc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8efa486c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 89\n",
      "[LightGBM] [Info] Number of data points in the train set: 120, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.176574\n",
      "[LightGBM] [Info] Start training from score -1.003302\n",
      "[LightGBM] [Info] Start training from score -1.123930\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttrain's multi_logloss: 0.0633269\tval's multi_logloss: 0.11451\n"
     ]
    }
   ],
   "source": [
    "# LGBM\n",
    "\n",
    "mlflow.lightgbm.autolog()\n",
    "\n",
    "# lgbm data format\n",
    "dtrain = lgb.Dataset(x_train, label=y_train)\n",
    "dval = lgb.Dataset(x_val, label=y_val)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # train model\n",
    "    pp = {'objective': 'multiclass'}\n",
    "    pp.update(params)\n",
    "    model_lgb = lgb.train(\n",
    "        params = pp,\n",
    "        train_set = dtrain,\n",
    "        valid_sets = [dtrain, dval],\n",
    "        valid_names = ['train', 'val'],\n",
    "        **train_params,\n",
    "    )\n",
    "    # evaluate model\n",
    "    y_proba = model_lgb.predict(x_val)\n",
    "    log_metrics(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e223041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:19:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"num_leaves\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[08:19:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-mlogloss:0.97647\tval-mlogloss:0.98181\n",
      "[50]\ttrain-mlogloss:0.06091\tval-mlogloss:0.09176\n",
      "[64]\ttrain-mlogloss:0.04813\tval-mlogloss:0.09109\n"
     ]
    }
   ],
   "source": [
    "# XGBM\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "# xgboost data format\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dval = xgb.DMatrix(x_val, label=y_val)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    pp = {'objective': 'multi:softprob'}\n",
    "    pp.update(params)\n",
    "    # train model\n",
    "    model_xgb = xgb.train(\n",
    "        params = pp,\n",
    "        dtrain = dtrain,\n",
    "        evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "        **train_params,\n",
    "    )\n",
    "    # evaluate model\n",
    "    y_proba = model_xgb.predict(dval)\n",
    "    log_metrics(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5479b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
